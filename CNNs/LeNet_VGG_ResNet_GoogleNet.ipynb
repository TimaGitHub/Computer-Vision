{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"z4u0APbJnscy"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torchvision\n","from torchvision.transforms import transforms\n","import matplotlib.pyplot as plt\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GDjhRE3bnu03"},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","source":["torchvision.datasets.cif"],"metadata":{"id":"9du8hihg_Qz-"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":304},"executionInfo":{"elapsed":406,"status":"error","timestamp":1714077612187,"user":{"displayName":"Bb Bb","userId":"08846771415044139021"},"user_tz":-180},"id":"B9G0BwxroW2M","outputId":"e945165e-3b4e-40b3-fecf-9fce2d213363"},"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"module 'torchvision.datasets' has no attribute 'CIFAR1000'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-561edee1bc6a>\u001b[0m in \u001b[0;36m<cell line: 36>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-3-561edee1bc6a>\u001b[0m in \u001b[0;36mget_dataset\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     train_dataset = torchvision.datasets.CIFAR1000(root = './data',\n\u001b[0m\u001b[1;32m     25\u001b[0m                                                 \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                                                 \u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrap_dataset_for_transforms_v2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"module {__name__!r} has no attribute {name!r}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mAttributeError\u001b[0m: module 'torchvision.datasets' has no attribute 'CIFAR1000'"]}],"source":["def get_dataset(name = 'm'):\n","  if name == 'm':\n","    train_dataset = torchvision.datasets.MNIST(root = './data',\n","                                                train = True,\n","                                                transform = transforms.ToTensor(),\n","                                                download = True)\n","\n","    test_dataset = torchvision.datasets.MNIST(root = './data',\n","                                                train = False,\n","                                                transform = transforms.ToTensor(),\n","                                                download = True)\n","  elif name == 'c':\n","    train_dataset = torchvision.datasets.CIFAR10(root = './data',\n","                                                train = True,\n","                                                transform = transforms.ToTensor(),\n","                                                download = True)\n","\n","    test_dataset = torchvision.datasets.CIFAR10(root = './data',\n","                                                train = False,\n","                                                transform = transforms.ToTensor(),\n","                                                download = True)\n","  return train_dataset, test_dataset\n","\n","\n","train_dataset, test_dataset = get_dataset(name = 'c')\n","batch_size = 64"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"obqsvS7wo4uu"},"outputs":[],"source":["train_loader = torch.utils.data.DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True)\n","test_loader = torch.utils.data.DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle = True)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d0omq9JlpFlR"},"outputs":[],"source":["# @title\n","\n","num_layers = 2\n","num_epochs = 20\n","n_classes = 10\n","batch_size = 64\n","learning_rate = 0.001\n","\n","class LeNet(nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","    self.cnn1 = nn.Conv2d(in_channels = 3,out_channels = 16, kernel_size = (5,5)) # MNIST 24x24, CIFAR 28x28\n","    self.act1 = nn.ReLU()\n","    self.maxpool1 = nn.MaxPool2d(kernel_size = (2,2)) # MNIST 12x12, CIFAR 14x14\n","    self.cnn2 = nn.Conv2d(in_channels = 16,out_channels = 32, kernel_size = (5,5), ) # MNIST8*8, CIFAR 10x10\n","    self.act2 = nn.ReLU()\n","    self.maxpool2 = nn.MaxPool2d(kernel_size = (2,2)) # MNIST4x4 CIFAR 5x5\n","    self.drop1 = nn.Dropout2d(0.25)\n","    self.flatten = nn.Flatten()\n","    self.fc1 = nn.Linear(5 * 5 * 32, 100)\n","    self.act3 = nn.ReLU()\n","    self.fc2 = nn.Linear(100, 10)\n","\n","  def forward(self, x):\n","    x = self.maxpool1(self.act1(self.cnn1(x)))\n","    x = self.maxpool2(self.act2(self.cnn2(x)))\n","    #x = self.drop1(x)\n","    x = self.flatten(x)\n","    x = self.act3(self.fc1(x))\n","    x = self.fc2(x)\n","    return x\n","\n","\n","class TimaNet(nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","    self.act = nn.ReLU()\n","    self.maxpool = nn.MaxPool2d(kernel_size = (2,2))\n","    self.dropout = nn.Dropout(0.25)\n","    self.cnn1 = nn.Conv2d(in_channels = 3,out_channels = 32, kernel_size = (3,3)) #CIFAR 30x30\n","    self.cnn2 = nn.Conv2d(in_channels = 32,out_channels = 64, kernel_size = (4,4) ) # MNIST8*8, CIFAR 12x12\n","    self.cnn3 = nn.Conv2d(in_channels = 64,out_channels = 64, kernel_size = (3,3) ) # MNIST8*8, CIFAR 10x10\n","    self.cnn4 = nn.Conv2d(in_channels = 64,out_channels = 64, kernel_size = (3,3), ) # MNIST8*8, CIFAR 3x3\n","    self.flatten = nn.Flatten()\n","    self.fc1 = nn.Linear(3 * 3 * 64, 1000)\n","    self.fc2 = nn.Linear(1000, 10)\n","\n","  def forward(self, x):\n","    x = self.maxpool(self.act(self.cnn1(x)))\n","    x = self.dropout(x)\n","    x = self.act(self.cnn2(x))\n","    x = self.maxpool(self.act(self.cnn3(x)))\n","    x = self.dropout(x)\n","    x = self.act(self.cnn4(x))\n","    x = self.dropout(x)\n","    x = self.flatten(x)\n","    x = self.act(self.fc1(x))\n","    x = self.fc2(x)\n","    return x\n","\n","class VGG(nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","    # INPUT (224, 224, 3)\n","\n","    self.act = nn.ReLU()\n","    self.maxpool = nn.MaxPool2d(kernel_size = (2,2))\n","\n","    self.cnn1 = nn.Conv2d(in_channels = 3, out_channels = 64, kernel_size = (3,3), padding = (1, 1), stride = (1,1))\n","    self.cnn2 = nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = (3,3), padding = (1, 1), stride = (1,1))\n","\n","    self.cnn3 = nn.Conv2d(in_channels = 64, out_channels = 128, kernel_size = (3,3), padding = (1, 1), stride = (1,1))\n","    self.cnn4 = nn.Conv2d(in_channels = 128, out_channels = 128, kernel_size = (3,3), padding = (1, 1), stride = (1,1))\n","\n","    self.cnn5 = nn.Conv2d(in_channels = 128, out_channels = 256, kernel_size = (3,3), padding = (1, 1), stride = (1,1))\n","    self.cnn6 = nn.Conv2d(in_channels = 256, out_channels = 256, kernel_size = (3,3), padding = (1, 1), stride = (1,1))\n","\n","    self.cnn7 = nn.Conv2d(in_channels = 256,out_channels = 512, kernel_size = (3,3), padding = (1, 1), stride = (1,1))\n","    self.cnn8 = nn.Conv2d(in_channels = 512,out_channels = 512, kernel_size = (3,3), padding = (1, 1), stride = (1,1))\n","    self.cnn9 = nn.Conv2d(in_channels = 512,out_channels = 512, kernel_size = (3,3), padding = (1, 1), stride = (1,1))\n","\n","    self.cnn10 = nn.Conv2d(in_channels = 512,out_channels = 512, kernel_size = (3,3), padding = (1, 1), stride = (1,1))\n","    self.cnn11 = nn.Conv2d(in_channels = 512,out_channels = 512, kernel_size = (3,3), padding = (1, 1), stride = (1,1))\n","    self.cnn12 = nn.Conv2d(in_channels = 512,out_channels = 512, kernel_size = (3,3), padding = (1, 1), stride = (1,1))\n","\n","    self.flatten = nn.Flatten()\n","    self.fc1 = nn.Linear(5 * 5 * 128, 25088)\n","    self.fc2 = nn.Linear(25088, 4096)\n","    self.fc3 = nn.Linear(4096, 4096)\n","    self.fc4 = nn.Linear(4096, 1000)\n","\n","  def forward(self, x):\n","\n","    x = self.act(self.cnn1(x))\n","    x = self.act(self.cnn2(x))\n","    x = self.maxpool(x)\n","\n","    x = self.act(self.cnn3(x))\n","    x = self.act(self.cnn4(x))\n","    x = self.maxpool(x)\n","\n","    x = self.act(self.cnn5(x))\n","    x = self.act(self.cnn6(x))\n","    x = self.maxpool(x)\n","\n","    x = self.act(self.cnn7(x))\n","    x = self.act(self.cnn8(x))\n","    x = self.act(self.cnn9(x))\n","    x = self.maxpool(x)\n","\n","    x = self.act(self.cnn10(x))\n","    x = self.act(self.cnn11(x))\n","    x = self.act(self.cnn12(x))\n","    x = self.maxpool(x)\n","\n","    x = self.flatten(x)\n","    x = self.act(self.fc1(x))\n","    x = self.act(self.fc2(x))\n","    x = self.act(self.fc3(x))\n","    x = self.act(self.fc4(x))\n","\n","    return x\n","\n","\n","class GoogleNet(nn.Module):\n","\n","  class conv_block(nn.Module):\n","    def __init__(self, in_channels, out_channels, **kwargs):\n","      super().__init__()\n","      self.relu = nn.ReLU()\n","      self.conv = nn.Conv2d(in_channels, out_channels)\n","      self.batchnorm = nn.BatchNorm2d(out_channels)\n","\n","    def forward(self, x):\n","      return self.relu(self.batchnorm(self.conv(x)))\n","\n","  class inception_block(nn.Module):\n","\n","    def __init__(self, in_channels, out_channels_1x1,  red_3x3, out_channels_3x3,  red_5x5, out_channels_5x5,  out_channels_max_1x1):\n","      super().__init__()\n","\n","      self.branch1 = conv_block(in_channels, out_channels_1x1, filter_size = 1)\n","      self.branch2 = nn.Sequentional(conv_block(in_channels, red_3x3, filter_size = 1),\n","                                      conv_block(red_3x3, out_channels_3x3, filter_size = (3,3), padding = 'same')\n","                                      )\n","      self.branch3 = nn.Sequentional(conv_block(in_channels, red_5x5, filter_size = 1),\n","                                      conv_block(red_5x5, out_channels_5x5, filter_size = (5,5), padding = 'same')\n","                                      )\n","      self.branch4 = nn.Sequentional(nn.MaxPool2d(kernel_size = 3, stride = 1, paddinf = 1),\n","                                      conv_block(in_channels, out_channels_max_1x1, filter_size = 1)\n","                                      )\n","    def forward(self, x):\n","      x1 = self.branch1(x)\n","      x2 = self.branch2(x)\n","      x3 = self.branch3(x)\n","      x4 = self.branch4(x)\n","      return torch.cat([x1, x2, x3, x4], dim = 1)\n","\n","\n","    def __init__(self, in_cahnnels = 3, num_classes = 1000):\n","      super().__init__()\n","      self.conv1 = conv_block(in_channels = in_channels, out_channels = 64, filter_size = (7,7), stride = (2,2), padding = (3,3))\n","      self.maxpool1 = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n","\n","      self.conv2 = conv_block(in_channels = 64, out_channels = 192, filter_size = (3,3), stride = (1,1), padding = (1,1))\n","      self.maxpool2 = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n","\n","      self.inception3a = inception_block(in_channels = 192, out_channels_1x1 = 64, red_3x3 = 96, out_channels_3x3 = 128, red_5x5 = 16, out_channels_5x5 = 32, out_channels_max_1x1 = 32)\n","      self.inception3b = inception_block(in_channels = 256, out_channels_1x1 = 128, red_3x3 = 128, out_channels_3x3 = 192, red_5x5 = 32, out_channels_5x5 = 96, out_channels_max_1x1 = 64)\n","      self.maxpool3 = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n","      self.inception4a = inception_block(in_channels = 480, out_channels_1x1 = 192, red_3x3 = 96, out_channels_3x3 = 208, red_5x5 = 16, out_channels_5x5 = 48, out_channels_max_1x1 = 64)\n","      self.inception4b = inception_block(in_channels = 512, out_channels_1x1 = 160, red_3x3 = 112, out_channels_3x3 = 224, red_5x5 = 24, out_channels_5x5 = 64, out_channels_max_1x1 = 64)\n","      self.inception4c = inception_block(in_channels = 512, out_channels_1x1 = 128, red_3x3 = 128, out_channels_3x3 = 256, red_5x5 = 24, out_channels_5x5 = 64, out_channels_max_1x1 = 64)\n","      self.inception4d = inception_block(in_channels = 512, out_channels_1x1 = 112, red_3x3 = 144, out_channels_3x3 = 288, red_5x5 = 32, out_channels_5x5 = 64, out_channels_max_1x1 = 64)\n","      self.inception4e = inception_block(in_channels = 528, out_channels_1x1 = 256, red_3x3 = 160, out_channels_3x3 = 320, red_5x5 = 32, out_channels_5x5 = 128, out_channels_max_1x1 = 128)\n","\n","      self.maxpool4 = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n","\n","      self.inception5a = inception_block(in_channels = 832, out_channels_1x1 = 256, red_3x3 = 160, out_channels_3x3 = 320, red_5x5 = 32, out_channels_5x5 = 128, out_channels_max_1x1 = 128)\n","      self.inception5b = inception_block(in_channels = 832, out_channels_1x1 = 384, red_3x3 = 192, out_channels_3x3 = 384, red_5x5 = 48, out_channels_5x5 = 128, out_channels_max_1x1 = 128)\n","\n","      self.avgpool = nn.AvgPool2d (kernel_size = 7, stride = 1)\n","\n","      self.dropout = nn.Dropout(0.4)\n","\n","      self.flatten = nn.Flatten()\n","\n","      self.linear = nn.Linear(in_features = 1024, out_features = 1000)\n","\n","    def forward(self, x):\n","      x = self.conv1(x)\n","      x = self.maxpool1(x)\n","      x = self.conv2(x)\n","      x = self.maxpool2(x)\n","      x = self.inception3a(x)\n","      x = self.inception3b(x)\n","      x = self.maxpool3(x)\n","      x = self.inception4a(x)\n","      x = self.inception4b(x)\n","      x = self.inception4c(x)\n","      x = self.inception4d(x)\n","      x = self.inception4e(x)\n","      x = self.maxpool4(x)\n","      x = self.inception5a(x)\n","      x = self.inception5b(x)\n","      x = self.avgpool(x)\n","      x = self.dropout(x)\n","      x = self.flatten(x)\n","      x = self.linear(x)\n","\n","      return x\n","\n","class ResNet(nn.Module):\n","\n","  class block(nn.Module):\n","    def __init__(self, in_channels, out_channels, identity_downsamle = None, stride = 1):\n","      super().init()\n","      self.expansion = 4\n","      self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size = 1, stride = 1, padding = 0)\n","      self.bn1 = nn.BatchNorm2d(out_channels)\n","      self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size = 3, stride = stride, padding = 1)\n","      self.bn2 = nn.BatchNorm2d(out_channels)\n","      self.conv3 = nn.Conv2d(out_channels, out_channels * self.expansion, kernel_size = 1, stride = 1, padding = 0)\n","      self.bn3 = nn.BatchNorm2d(out_channels * self.expansion)\n","      self.relu = nn.ReLU()\n","      self.identity_downsamle = identity_downsamle\n","\n","    def forward(self, x):\n","      identity = x\n","      x = self.conv1(x)\n","      x = self.bn1(x)\n","      x = self.relu(x)\n","      x = self.conv2(x)\n","      x = self.bn2(x)\n","      x = self.relu(x)\n","      x = self.conv3(x)\n","      x = self.bn3(x)\n","      x = self.relu(x)\n","\n","      if self.identity_downsamle is not None:\n","        identity = self.identity_downsamle(identity)\n","\n","      x += identity\n","      x = self.relu(x)\n","\n","      return x\n","\n","  def __init__(self, block, layers, image_channels, num_classes):\n","    super().init()\n","    self.in_channels = 64\n","    self.conv1 = nn.Conv2d(image_channels, out_channels = 64, kernel_size = 7, stride = 2, padding = 3)\n","    self.bn1 = nn.BatchNorm2d(64)\n","    self.relu = nn.ReLU()\n","    self.maxpool = nn.MaxPool2d(kernel_size=3, stride =2, padding = 1)\n","\n","    self.layer1 = self._make_layer(block, layers[0], out_channels = 64, stride = 1)\n","    self.layer2 = self._make_layer(block, layers[1], out_channels = 128, stride = 2)\n","    self.layer3 = self._make_layer(block, layers[2], out_channels = 256, stride = 2)\n","    self.layer4 = self._make_layer(block, layers[3], out_channels = 512, stride = 2)\n","\n","    self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n","    self.fc = nn.Linear(512 * 4, num_classes)\n","\n","  def forward(self, x):\n","    x = self.conv1(x)\n","    x = self.bn1(x)\n","    x = self.relu(x)\n","\n","    x = self.layer1(x)\n","    x = self.layer2(x)\n","    x = self.layer3(x)\n","    x = self.layer4(x)\n","\n","    x = self.avgpool(x)\n","    x = x.reshape(x.shape[0], -1)\n","    x = self.fc(x)\n","\n","  def _make_layer(self, block, number_residual_blocks, out_channels, stride):\n","    identity_downsamle = None\n","    layers = []\n","\n","    if stride != 1 or self.in_channels != out_channels * 4:\n","      identity = nn.Sequential(nn.Conv2d(self.in_channels, out_channels * 4, kernel_size =1, stride = stride), nn.BatchNorm1d(out_channels * 4))\n","\n","    layers.append(block(self.in_channels, out_channels, identity_downsamle, stride))\n","    self.in_channels = out_channels * 4\n","\n","    for i in range(number_residual_blocks - 1):\n","      layers.append(block(self.in_channels, out_channels))\n","\n","    return nn.Sequential(*layers)\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XE9oKDIYqnIU"},"outputs":[],"source":["model = GoogleNet().to(device)\n","\n","loss_fn = nn.CrossEntropyLoss()\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate, betas=(0.9, 0.9))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h848JHVQrOq4"},"outputs":[],"source":["for epoch in range(num_epochs):\n","  for i, (image, label) in enumerate(train_loader):\n","    image = image.to(device)\n","    label = label.to(device).long()\n","    logits = model(image)\n","    loss = loss_fn(logits, label)\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","    if (i + 1) % 100 == 0:\n","      test_acc = 0\n","      train_acc = torch.sum((label.reshape(image.shape[0], 1)[:,0] == torch.argmax(logits, axis = 1))) / image.shape[0]\n","      with torch.no_grad():\n","        for j, (image, label) in enumerate(test_loader):\n","          batch_temp_size = image.shape[0]\n","          image = image.to(device)\n","          label = label.to(device).long()\n","          logits = model(image)\n","          test_acc += torch.sum((label.reshape(batch_temp_size, 1)[:,0] == torch.argmax(logits, axis = 1))) / batch_temp_size\n","        test_acc = test_acc / (j + 1)\n","        print(f\"Epoch [{epoch + 1} / {num_epochs}], Step {i + 1} / {len(train_loader)}, loss {loss.item():.4f}, test accuracy {test_acc:2f}, train accuracy {train_acc:2f}\")"]},{"cell_type":"code","source":[],"metadata":{"id":"cc1F0mLLParh"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPZ5eOSrvLAETCN+sas2EgZ"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}