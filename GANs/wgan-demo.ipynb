{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch \nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision.datasets as datasets\nimport torchvision.transforms as transforms\nimport torchvision\nfrom torch.utils.data import DataLoader\nfrom torch.utils.tensorboard import SummaryWriter\nfrom tqdm.auto import tqdm\nimport matplotlib.pyplot as plt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-26T10:30:37.757297Z","iopub.execute_input":"2024-06-26T10:30:37.757670Z","iopub.status.idle":"2024-06-26T10:30:58.815107Z","shell.execute_reply.started":"2024-06-26T10:30:37.757641Z","shell.execute_reply":"2024-06-26T10:30:58.813788Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-06-26 10:30:46.786380: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-26 10:30:46.786504: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-26 10:30:46.967526: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"class Critic(nn.Module):\n    def __init__(self, channels, features):\n        super().__init__()\n        self.disc = nn.Sequential(\n            #Input 64x64\n            nn.Conv2d(channels, features, kernel_size = 4, stride = 2, padding = 1),\n            nn.LeakyReLU(0.2),\n            # 32x32\n            self._block(features, features*2, 4, 2, 1),# 16x16\n            self._block(features*2, features*4, 4, 2, 1),# 8x8\n            self._block(features*4, features*8, 4, 2, 1), # 4x4\n            nn.Conv2d(features*8, 1, kernel_size = 4, stride = 2, padding = 0), # 1x1\n        )\n        \n    def _block(self, in_channels, out_channels, kernel, stride, padding):\n        return nn.Sequential(\n        nn.Conv2d(in_channels, out_channels, kernel, stride, padding),\n        nn.LeakyReLU(0.2),\n        #nn.BatchNorm2d(out_channels)\n        )\n    \n    def forward(self, x):\n        return self.disc(x)\n    \n    \nclass Generator(nn.Module):\n    def __init__(self, z_dim, channels, features):\n        super().__init__()\n        self.net = nn.Sequential(\n            # Input 1x1\n            self._block(z_dim, features*16, 4, 1, 0),# 4x4\n            self._block(features*16, features*8, 4, 2, 1), # 8x8\n            self._block(features*8, features*4, 4, 2, 1), # 16x16\n            self._block(features*4, features*2, 4, 2, 1), # 32x32\n            nn.ConvTranspose2d(features*2, # 64x64\n                              channels,\n                              4,\n                              2,\n                              1),\n            nn.Sigmoid()\n        )\n        \n    def _block(self, in_channels, out_channels, kernel, stride, padding):\n        return nn.Sequential(\n            nn.ConvTranspose2d(in_channels, \n                              out_channels,\n                              kernel,\n                              stride,\n                              padding),\n            nn.ReLU(),\n            nn.BatchNorm2d(out_channels)\n        )\n    \n    def forward(self, x):\n        return self.net(x)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T10:30:58.817641Z","iopub.execute_input":"2024-06-26T10:30:58.818282Z","iopub.status.idle":"2024-06-26T10:30:58.831065Z","shell.execute_reply.started":"2024-06-26T10:30:58.818248Z","shell.execute_reply":"2024-06-26T10:30:58.829643Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nLR = 2e-4\nBS = 128\nIMGS = 64\nCHANNELS = 1\nZDIM = 16\nEPOCHS = 100\nFEATURES_DISC = 64\nFEATURES_GEN = 64\nCRITIC_ITER = 5\nWEIGHT_CLIP = 0.01","metadata":{"execution":{"iopub.status.busy":"2024-06-26T10:30:58.837020Z","iopub.execute_input":"2024-06-26T10:30:58.837907Z","iopub.status.idle":"2024-06-26T10:30:58.847129Z","shell.execute_reply.started":"2024-06-26T10:30:58.837847Z","shell.execute_reply":"2024-06-26T10:30:58.845802Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"transform = transforms.Compose(\n        \n                [   transforms.Resize(IMGS),\n                    transforms.ToTensor()]\n                )\n\n# dataset = datasets.CIFAR10('../data', train=True, download=True,\n#                        transform=transform)\ndataset = datasets.MNIST('../data', train=True, download=True,\n                       transform=transform)\n\n# num = (5, 1)\n# dataset = [x for x in dataset if x[1] in num]\ntrain_loader = torch.utils.data.DataLoader(dataset, batch_size = BS)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T10:30:58.848783Z","iopub.execute_input":"2024-06-26T10:30:58.849169Z","iopub.status.idle":"2024-06-26T10:31:04.187140Z","shell.execute_reply.started":"2024-06-26T10:30:58.849131Z","shell.execute_reply":"2024-06-26T10:31:04.185716Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\nFailed to download (trying next):\nHTTP Error 403: Forbidden\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 9912422/9912422 [00:00<00:00, 12880761.74it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz to ../data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\nFailed to download (trying next):\nHTTP Error 403: Forbidden\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 28881/28881 [00:00<00:00, 364964.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\nFailed to download (trying next):\nHTTP Error 403: Forbidden\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1648877/1648877 [00:00<00:00, 3370908.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\nFailed to download (trying next):\nHTTP Error 403: Forbidden\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 4542/4542 [00:00<00:00, 1450916.13it/s]","output_type":"stream"},{"name":"stdout","text":"Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw\n\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"gen = Generator(ZDIM, CHANNELS, FEATURES_GEN)\ncritic = Critic(CHANNELS, FEATURES_DISC)\n\ngen.to(device)\ncritic.to(device)\n\nloss_fn = nn.BCELoss()\n\noptim_gen = torch.optim.RMSprop(gen.parameters(), lr = LR)\noptim_critic = torch.optim.RMSprop(critic.parameters(), lr = LR)\n\nwriter_real = SummaryWriter(f\"logs/real\")\nwriter_fake = SummaryWriter(f\"logs/fake\")\nstep = 0","metadata":{"execution":{"iopub.status.busy":"2024-06-26T10:31:04.188906Z","iopub.execute_input":"2024-06-26T10:31:04.189296Z","iopub.status.idle":"2024-06-26T10:31:04.389634Z","shell.execute_reply.started":"2024-06-26T10:31:04.189262Z","shell.execute_reply":"2024-06-26T10:31:04.388445Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"for epoch in tqdm(range(EPOCHS)):\n    for index, (image, label) in enumerate(train_loader):\n        gen.train()\n        critic.train()\n        \n        for  _ in range(CRITIC_ITER):\n            sample = torch.randn(BS, ZDIM, 1, 1).to(device)\n            fake = gen(sample)\n            \n            fake_output = critic(fake.detach()).reshape(-1)\n            real_output = critic(image.to(device)).reshape(-1)\n            loss_critic = -(torch.mean(real_output) - torch.mean(fake_output))\n            critic.zero_grad()\n            loss_critic.backward()\n            optim_critic.step()\n            \n            for p in critic.parameters():\n                p.data.clamp_(-WEIGHT_CLIP, WEIGHT_CLIP)\n        \n        fake_output = critic(fake).reshape(-1)\n        gen_loss = -torch.mean(fake_output)\n        gen.zero_grad()\n        gen_loss.backward()\n        optim_gen.step()\n        \n        if index % 100 == 0:\n            print(\n            f\"Epoch [{epoch}/{EPOCHS}] Batch {index}/{len(train_loader)} \\\n            Loss D: {dis_loss.item():.4f}, Loss G: {gen_loss.item():.4f}\"\n            )\n            \n            with torch.no_grad():\n                gen.eval()\n                sample = torch.randn(BS, ZDIM, 1, 1).to(device)\n                fake = gen(sample)\n                img_grid_real = torchvision.utils.make_grid(\n                    image[:32], normalize = True)\n                img_grid_fake = torchvision.utils.make_grid(\n                    fake[:32], normalize = True)\n                \n                writer_real.add_image(\"Real\", img_grid_real, global_step = step)\n                writer_fake.add_image(\"Real\", img_grid_fake, global_step = step)\n            step += 1\n            \n    plt.figure(figsize=(20, 8))\n\n    for i in range(1, 6):\n        plt.subplot(2,5,i)\n        plt.imshow(image[i - 1].cpu().detach().permute(1,2,0).numpy())\n        plt.axis('off')\n    for i in range(6, 11):\n        plt.subplot(2,5, i)\n        plt.imshow(fake[i - 6].cpu().detach().permute(1,2,0).numpy())\n        plt.axis('off')\n    plt.show()\n            ","metadata":{},"execution_count":null,"outputs":[]}]}